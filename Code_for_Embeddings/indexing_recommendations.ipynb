{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Gajraj')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "info['stargazers_count']-y\n",
    "\n",
    "info['forks_count']-y\n",
    "\n",
    "info['license']-y\n",
    "\n",
    "info['private']\n",
    "\n",
    "info['github_contributions_count']-y\n",
    "\n",
    "info['contributions_count']-y\n",
    "\n",
    "Dependent count -y\n",
    "\n",
    "info['last_synced_at'] Release date - y\n",
    "\n",
    "len(info['dependencies'])\n",
    "\n",
    "release_count -> using github api\n",
    "\n",
    "activity --> Research\n",
    "\n",
    "'https://github.com/'+info['full_name']+'.git'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Base Ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install duckdb\n",
    "# !pip install pybraries\n",
    "# !pip install PyGithub\n",
    "# !pip install langchain cohere huggingface-hub\n",
    "# !pip uninstall chromadb -y\n",
    "# !pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"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\"\n",
    "os.environ[\"COHERE_API_KEY\"] = \"EoYcDiVFH7gW1AMTpSj6YCrMPwHF7lR2JW5PGsGJ\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "path = '/workspaces/pythonenv/code-space-blank-repo/Code_for_Embeddings'\n",
    "account_vulnerabilities_df=pd.read_csv(f'{path}/data/account_vulnerabilities.csv')\n",
    "public_tools_df=pd.read_csv(f'{path}/data/public_tools.csv')\n",
    "versions_data_df=pd.read_csv(f'{path}/data/versions_data.csv')\n",
    "vulnerabilities_df=pd.read_csv(f'{path}/data/vulnerabilities.csv')\n",
    "decisions_data_df=pd.read_csv(f'{path}/data/decisions_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "duckdb.default_connection.execute(\"SET GLOBAL pandas_analyze_sample=100000\")\n",
    "def sql_helper(sql):\n",
    "    return duckdb.query(sql).to_df()\n",
    "\n",
    "def sql_helper_one(sql):\n",
    "    return duckdb.query(sql).fetchone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# id, name, type, description, category, function, layer, latest_version_number,package_manager\n",
    "pd.set_option(\"display.max_colwidth\", 500)\n",
    "sql=f\"\"\"\n",
    "select \n",
    "    vd.tool_id,vd.tool_name,vd.version_range,vd.severity,vd.first_patched_version\n",
    "from \n",
    "    vulnerabilities_df as vd\n",
    "inner join\n",
    "    public_tools_df as ptd  \n",
    "on\n",
    "    vd.tool_id = ptd.id        \n",
    "\"\"\"\n",
    "vulnerabilities_info_df = sql_helper(sql)\n",
    "vulnerabilities_info_df.to_csv('stuff.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['< 4.18.2']\n",
      "one node\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "def get_tool_wise_version_number(tool_id):\n",
    "    sql=f\"\"\"\n",
    "    select \n",
    "        row_number() OVER (ORDER BY number) AS row_no,\n",
    "        number,\n",
    "        tool_id,\n",
    "        0 as tool_version_security_vulnerabilities\n",
    "    from versions_data_df\n",
    "    where tool_id = {tool_id}\n",
    "    order by number\n",
    "    \"\"\"\n",
    "    return sql_helper(sql)\n",
    "\n",
    "def get_row_ids_for_severity(tool_id, min_version=None, max_version=None):\n",
    "    for inx,item in get_tool_wise_version_number(tool_id).iterrows():\n",
    "        print(inx)\n",
    "\n",
    "for inx,item in vulnerabilities_info_df.iterrows():\n",
    "\n",
    "    if inx < 1:\n",
    "        min_range=''\n",
    "        max_range=''\n",
    "        version_range = json.loads(item.version_range)[0].split(',')\n",
    "        # print(version_range)\n",
    "        if len(version_range) == 1:\n",
    "            max_range=version_range[0]\n",
    "            stuff = f'''\n",
    "                    Can you give list of row_no from followings data whose number is within range of <min> and {max_range.replace('<','').replace('=','')}\n",
    "            row_no number\n",
    "                    '''.strip()\n",
    "            # print('one node')\n",
    "        else:\n",
    "            min_range=version_range[0]\n",
    "            max_range=version_range[1]\n",
    "            stuff = f'''\n",
    "                    Can you give list of row_no from followings data whose number is within range of {min_range.replace('<','').replace('=','')} and {max_range.replace('>','').replace('=','')}\n",
    "            row_no number\n",
    "                    '''.strip()\n",
    "            print('two node')\n",
    "\n",
    "        \n",
    "        df = get_tool_wise_version_number(item.tool_id)\n",
    "        for inx,item in df.iterrows():\n",
    "            if inx == 0 and len(version_range) == 1:\n",
    "                stuff.replace(\"<min>\",item.number)\n",
    "                min_range = item.number\n",
    "                stuff = f'''\n",
    "                        Can you give list of row_no from followings data whose number is within range of {min_range.replace('<','').replace('=','')} and {max_range.replace('>','').replace('=','')}\n",
    "                row_no number\n",
    "                        '''.strip()\n",
    "\n",
    "            stuff += f'\\n {item.row_no}, {item.number}'\n",
    "\n",
    "        # print(f\"Data Exists --> {(min_range if len(max_range)==0 else max_range) in stuff} -- {max_range.replace('>','').replace('=','')}\")\n",
    "        max_range = ''\n",
    "        min_range = ''    \n",
    "    else:\n",
    "        break\n",
    "\n",
    "    # print(stuff)   \n",
    "    # with open('gd.txt','w') as file:\n",
    "    #     file.write(stuff)\n",
    "    # print('--------------------------------------------') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_tool_wise_version_number(15904)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Related ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql=f\"\"\"\n",
    "    select \n",
    "        number as version_number, \n",
    "        tool_id,\n",
    "        tool_name,\n",
    "        trusted,\n",
    "        released_at,\n",
    "        major_version_number,\n",
    "        commit_url,\n",
    "        source_url,\n",
    "        release_source,\n",
    "        \"detected in # of stacks\" as no_of_stacks,\n",
    "        lts,\n",
    "        \"end of life at\" as eol_info,\n",
    "        \"end of active support at\" as support_info,\n",
    "        0 as tool_version_External_Factors_Freshness_Distance_from_latest_version,\n",
    "        0 as tool_version_External_Factors_Freshness_EOL_Support,\n",
    "        0 as tool_version_External_Factors_Last_commit_date_of_the_package,\n",
    "        0 as tool_version_External_Factors_Security_Vulnerabilities,\n",
    "        0 as star_count,\n",
    "        0 as forks_count,\n",
    "        0 as watch_count,\n",
    "        0 as release_count,\n",
    "        current_date as last_release_date,\n",
    "        0 as contributor_count,\n",
    "        '' as license,\n",
    "        0 as activiy,\n",
    "        0 as Dependent_count,\n",
    "        0 as Repo_Count_For_A_Tools,\n",
    "        0 as Repo_Count_For_A_Tools_Current_Version,\n",
    "        '' as Repo_Count_For_A_Tools_Version_wise,\n",
    "        0 as score\n",
    "    from \n",
    "        versions_data_df\n",
    "            where tool_id in \n",
    "                (\n",
    "                select id\n",
    "                from \n",
    "                    public_tools_df\n",
    "                where \n",
    "                    category='Monitoring'\n",
    "                )\n",
    "            and\n",
    "                release_source in ('github','librariesio')\n",
    "            and\n",
    "                source_url is not NULL\n",
    "        order by release_source\n",
    "\"\"\"\n",
    "final=sql_helper(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"LIBRARIES_API_KEY\"] = \"3eb34b09ad28ccc4026d47b51a639114\"\n",
    "from pybraries.search import Search\n",
    "import time\n",
    "import github\n",
    "import requests\n",
    "import json\n",
    "from github import Github\n",
    "from github import Auth\n",
    "from git_info import *\n",
    "\n",
    "from git_info import *\n",
    "auth = Auth.Token(\"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\")\n",
    "\n",
    "search = Search()\n",
    "for inx,item in final.iterrows():\n",
    "    try:\n",
    "        print(item.tool_id,'-',item.version_number,'-',inx)\n",
    "        if item.release_source == 'github':\n",
    "            github_repo='/'.join(item.commit_url.split(\"/\")[-4:-2]).split('/')\n",
    "            # print(github_repo)\n",
    "            owner=github_repo[0]\n",
    "            reporef=github_repo[1]\n",
    "            info = search.repository_dependencies(host='github',owner=owner,repo=reporef)\n",
    "        else:\n",
    "            reporef = item.source_url.split(\"/\")[-2:-1][0]\n",
    "            host = ('npm' if 'npm' in item.source_url else 'github')\n",
    "            info = search.repository_dependencies(host=host,owner=reporef,repo=item.version_number)\n",
    "            # print(info)\n",
    "\n",
    "        final.at[inx,\"star_count\"] = info[('stars' if 'stargazers_count' not in info else 'stargazers_count')] #info['stargazers_count']\n",
    "        final.at[inx,\"forks_count\"] = info[('forks' if 'forks_count' not in info else 'forks_count')]\n",
    "        final.at[inx,\"contributor_count\"] = info['contributions_count']\n",
    "        final.at[inx,\"last_release_date\"] = info[('latest_release_published_at' if 'last_synced_at' not in info else 'last_synced_at')]\n",
    "        final.at[inx,\"license\"] = info[('licenses' if 'license' not in info else 'license')]\n",
    "        final.at[inx,\"Dependent_count\"] = (len(info['dependencies']) if item.release_source == 'github' else info['dependents_count'])\n",
    "        repo_name= (info['full_name'] if item.release_source == 'github' else '/'.join(info['repository_url'].split(\"/\")[-2:]))\n",
    "        final.at[inx,\"release_count\"]=get_release_count(repo_name=repo_name, auth=auth)\n",
    "        final.at[inx,\"watch_count\"]=get_watch_count(repo_name=repo_name, auth=auth)\n",
    "        final.at[inx,\"Repo_Count_For_A_Tools\"] = get_total_repo(item.tool_id)\n",
    "        final.at[inx,\"Repo_Count_For_A_Tools_Current_Version\"] = item.no_of_stacks\n",
    "        final.at[inx,\"Repo_Count_For_A_Tools_Version_wise\"] = json.dumps(get_Repo_Count_For_A_Tools_Version_wise(tool_id=item.tool_id))\n",
    "        # final.at[inx,\"activiy\"]=info['stargazers_count']\n",
    "        time.sleep(1)\n",
    "    except Exception as ex:\n",
    "        print(f'error --> {ex}')\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final[['star_count','forks_count','last_release_date','contributor_count','license','Dependent_count','release_count','watch_count','activiy','Repo_Count_For_A_Tools','Repo_Count_For_A_Tools_Current_Version','Repo_Count_For_A_Tools_Version_wise']]\n",
    "final.to_csv('result.csv',index=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate weightage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wdf=pd.read_csv('./result.csv')\n",
    "sql=\"\"\"\n",
    "    with gdb as (\n",
    "        select \n",
    "            max(version_number) as max_version_number,\n",
    "            tool_id\n",
    "        from wdf\n",
    "        group by tool_id),\n",
    "        finaldb as (\n",
    "            select * from wdf\n",
    "        )\n",
    "        select \n",
    "            g.tool_id,\n",
    "            f.version_number,\n",
    "            f.tool_name \n",
    "        from \n",
    "            finaldb as f\n",
    "        inner join \n",
    "            gdb as g\n",
    "        on f.tool_id = g.tool_id\n",
    "        order by g.tool_id,f.version_number desc;\n",
    "\"\"\"\n",
    "df=sql_helper(sql)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_version__Distance_df = pd.read_csv('../../target.csv')\n",
    "final = pd.read_csv('../../result.csv')\n",
    "sql = f\"\"\"\n",
    "select \n",
    "    f.version_number, \n",
    "    f.tool_id, \n",
    "    f.tool_name, \n",
    "    f.trusted, \n",
    "    f.released_at,\n",
    "    f.major_version_number, \n",
    "    f.commit_url, \n",
    "    f.source_url, \n",
    "    f.release_source,\n",
    "    f.no_of_stacks, \n",
    "    f.lts, \n",
    "    f.eol_info, \n",
    "    f.support_info,\n",
    "    tvd.Rank as tool_version_External_Factors_Freshness_Distance_from_latest_version,    \n",
    "    5 as tool_version_External_Factors_Freshness_EOL_Support,\n",
    "    f.tool_version_External_Factors_Last_commit_date_of_the_package,\n",
    "    f.tool_version_External_Factors_Security_Vulnerabilities, \n",
    "    f.star_count,\n",
    "    f.forks_count, \n",
    "    f.watch_count, \n",
    "    f.release_count, \n",
    "    f.last_release_date,\n",
    "    f.contributor_count, \n",
    "    f.license, \n",
    "    f.activiy, \n",
    "    f.Dependent_count,\n",
    "    f.Repo_Count_For_A_Tools, \n",
    "    f.Repo_Count_For_A_Tools_Current_Version,\n",
    "    f.Repo_Count_For_A_Tools_Version_wise, \n",
    "    f.score     \n",
    "from \n",
    "    tool_version__Distance_df as tvd\n",
    "inner join final as f\n",
    "on tvd.version_number = f.version_number;\n",
    "\"\"\"\n",
    "sql_helper(sql)\n",
    "# final.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents=pd.read_csv('./documentv1.csv')\n",
    "sql=f\"\"\"\n",
    "    select \n",
    "        version_number, \n",
    "        tool_id, \n",
    "        tool_name, \n",
    "        release_source,\n",
    "        tool_version_External_Factors_Freshness_Distance_from_latest_version,\n",
    "        tool_version_External_Factors_Last_commit_date_of_the_package,\n",
    "        tool_version_External_Factors_Security_Vulnerabilities, \n",
    "        star_count,\n",
    "        forks_count, \n",
    "        watch_count, \n",
    "        release_count, \n",
    "        contributor_count, \n",
    "        license, \n",
    "        Dependent_count,\n",
    "        score    \n",
    "from \n",
    "    documents;\n",
    "\"\"\"\n",
    "\n",
    "sourcedf=sql_helper(sql)\n",
    "source_dict={\n",
    "    'tool_version_External_Factors_Freshness_Distance_from_latest_version':10,\n",
    "    'tool_version_External_Factors_Last_commit_date_of_the_package':10,\n",
    "    'tool_version_External_Factors_Security_Vulnerabilities':20, \n",
    "    'star_count':10,\n",
    "    'forks_count':10, \n",
    "    'watch_count':5, \n",
    "    'release_count':5, \n",
    "    'contributor_count':10,\n",
    "    'license':10, \n",
    "    'Dependent_count':5\n",
    "}\n",
    "source_dict['tool_version_External_Factors_Freshness_Distance_from_latest_version']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(4/5)*5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for inx,item in sourcedf.iterrows():\n",
    "    score = (item.tool_version_External_Factors_Freshness_Distance_from_latest_version/5)*source_dict['tool_version_External_Factors_Freshness_Distance_from_latest_version']    \n",
    "    score += (item.tool_version_External_Factors_Freshness_Distance_from_latest_version/5)*source_dict['tool_version_External_Factors_Last_commit_date_of_the_package']    \n",
    "    score += (item.tool_version_External_Factors_Freshness_Distance_from_latest_version/5)*source_dict['tool_version_External_Factors_Security_Vulnerabilities']    \n",
    "    score += (item.tool_version_External_Factors_Freshness_Distance_from_latest_version/5)*source_dict['star_count']    \n",
    "    score += (item.tool_version_External_Factors_Freshness_Distance_from_latest_version/5)*source_dict['forks_count']    \n",
    "    score += (item.tool_version_External_Factors_Freshness_Distance_from_latest_version/5)*source_dict['watch_count']    \n",
    "    score += (item.tool_version_External_Factors_Freshness_Distance_from_latest_version/5)*source_dict['release_count']    \n",
    "    score += (item.tool_version_External_Factors_Freshness_Distance_from_latest_version/5)*source_dict['contributor_count']    \n",
    "    score += (item.tool_version_External_Factors_Freshness_Distance_from_latest_version/5)*source_dict['license']    \n",
    "    score += (item.tool_version_External_Factors_Freshness_Distance_from_latest_version/5)*source_dict['Dependent_count']    \n",
    "    sourcedf.at[inx,\"score\"] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sourcedf.to_csv('documentv2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents=pd.read_csv('./documentv2.csv')\n",
    "documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate recommandation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.cohere import CohereEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "documentsv2 = pd.read_csv('./documentv2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql=f\"\"\"\n",
    "select \n",
    "    row_number() OVER (PARTITION BY tool_id ORDER BY version_number) as rn,\n",
    "    * \n",
    "from documentsv2\n",
    "order by tool_id;\n",
    "\"\"\"\n",
    "documents=sql_helper(sql)\n",
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_conversion(item):\n",
    "    document=f\"\"\"\n",
    "        Description:\n",
    "            This document represent information about recommendation of solution based on user inputted query.\n",
    "            Where user need an answer in form of recommandation for perticular scenario.\n",
    "            It's following information\n",
    "            version_number:{item.version_number} \n",
    "            tool_id:{item.tool_id} \n",
    "            tool_name:{item.tool_name}\n",
    "            release_source:{item.release_source}\n",
    "            Distance from latest version:{item.tool_version_External_Factors_Freshness_Distance_from_latest_version}\n",
    "            Last commit date of the package:{item.tool_version_External_Factors_Last_commit_date_of_the_package}\n",
    "            Security Vulnerabilities:{item.tool_version_External_Factors_Security_Vulnerabilities}\n",
    "            star_count:{item.star_count}\n",
    "            forks_count:{item.forks_count} \n",
    "            watch_count:{item.watch_count} \n",
    "            release_count:{item.release_count}\n",
    "            contributor_count:{item.contributor_count}\n",
    "            license:{item.license}\n",
    "            Dependent_count:{item.Dependent_count}\n",
    "            score:{item.score}            \n",
    "            It'll help to recognize recommendation\n",
    "    \"\"\"\n",
    "    return document\n",
    "\n",
    "def fetch_value_from_df(item,element):\n",
    "    return list(item[element])[0]\n",
    "\n",
    "def convert_nodes_to_list(nodes):\n",
    "    statement = ''\n",
    "    for i in nodes:\n",
    "        statement += f\"\"\"\n",
    "            version #: {i[0].metadata['version_number']} -- score: {i[0].metadata['score']}\n",
    "                \"\"\".rstrip()\n",
    "    return statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.docstore.document import Document\n",
    "\n",
    "document_ids=[]\n",
    "original_docs=[]\n",
    "for inx,item in documents.iterrows():\n",
    "    initial_content = document_conversion(item)\n",
    "    document_id = str(item.version_number)\n",
    "    # print(initial_content)\n",
    "    # Create an instance of Document with initiald content and metadata\n",
    "    metadata_dict={\n",
    "    'inx':item.rn,    \n",
    "    \"version_number\":item.version_number, \n",
    "    \"tool_id\":item.tool_id,\n",
    "    \"tool_name\":item.tool_name,\n",
    "    \"release_source\":item.release_source,\n",
    "    \"Distance_from_latest_version\":item.tool_version_External_Factors_Freshness_Distance_from_latest_version,\n",
    "    \"Last_commit_date_of_the_package\":item.tool_version_External_Factors_Last_commit_date_of_the_package,\n",
    "    \"Security_Vulnerabilities\":item.tool_version_External_Factors_Security_Vulnerabilities,\n",
    "    \"star_count\":item.star_count,\n",
    "    \"forks_count\":item.forks_count, \n",
    "    \"watch_count\":item.watch_count, \n",
    "    \"release_count\":item.release_count,\n",
    "    \"contributor_count\":item.contributor_count,\n",
    "    \"license\":item.license,\n",
    "    \"Dependent_count\":item.Dependent_count,\n",
    "    \"score\":item.score}\n",
    "    original_doc = Document(page_content=initial_content, metadata=metadata_dict)\n",
    "    document_ids.append(document_id)\n",
    "    original_docs.append(original_doc)\n",
    "    # Initialize a Chroma instance with the original document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import CohereEmbeddings\n",
    "embeddings = CohereEmbeddings()\n",
    "db = FAISS.from_documents(original_docs, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_id=5577\n",
    "current_version='1.17.5'\n",
    "\n",
    "sql = f\"\"\"\n",
    "    select * \n",
    "    from documents\n",
    "    where \n",
    "        rn = (\n",
    "        select max(rn) \n",
    "        from documents\n",
    "        where tool_id = {tool_id}\n",
    "        )\n",
    "    AND\n",
    "        tool_id = {tool_id}\n",
    "\"\"\"\n",
    "get_highest_node = sql_helper(sql)\n",
    "sql = f\"\"\"\n",
    "    select * \n",
    "    from documents\n",
    "    where version_number = '{current_version}'\n",
    "\"\"\"\n",
    "get_current_node = sql_helper(sql)\n",
    "get_nodes=[]\n",
    "docs = db.similarity_search_with_score(current_version,K=10,fetch_k=30,filter={'tool_id':tool_id})\n",
    "for inx,i in enumerate(docs):\n",
    "    if i[0].metadata['inx'] > fetch_value_from_df(get_current_node,'rn'):\n",
    "        get_nodes.append(i)\n",
    "        # print(i[0].metadata['tool_id'],'-',i[0].metadata['version_number'],'-',i[0].metadata['inx'],'-',i[0].metadata['score'],'-',docs[inx][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommandation_statements=f\"\"\"\n",
    "    current score for this tool {fetch_value_from_df(get_current_node,'tool_name')}  with version {fetch_value_from_df(get_current_node,'version_number')} is -- {fetch_value_from_df(get_current_node,'score')}\n",
    "You are {int((fetch_value_from_df(get_highest_node,'score')- fetch_value_from_df(get_current_node,'score'))/fetch_value_from_df(get_current_node,'score')*100)}% far from Latest version of {fetch_value_from_df(get_current_node,'tool_name')}\n",
    "\"\"\".strip()\n",
    "print(recommandation_statements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import github\n",
    "import requests\n",
    "import json\n",
    "from github import Github\n",
    "from github import Auth\n",
    "from git_info import *\n",
    "auth = Auth.Token(\"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\")\n",
    "\n",
    "get_release_count(repo_name='prettier/prettier',auth=auth)\n",
    "# g = github.Github(auth=auth)\n",
    "# repo_name = info['full_name']\n",
    "# repo = g.get_repo(repo_name)\n",
    "# repo.stargazers_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vulnerabilities_df.columns\n",
    "#Need to ask chetan for version range\n",
    "#Issues and bugs detected\n",
    "#EOL\n",
    "#LTS\n",
    "#VERSION-DIFFERNCE\n",
    "#SCORE\n",
    "#IMPROVE SUGGESTION WITH SCORE\n",
    "# APP\n",
    "    # 1. TOOL-VERSION-SCORE -> SUGGESTION ONLY FOR VERSION\n",
    "    # APP->REPO->TOOLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# account_vulnerabilities_df.columns\n",
    "# public_tools_df.columns\n",
    "# account_vulnerabilities_df\n",
    "versions_data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id=3350\n",
    "sql = f\"\"\"\n",
    "    SELECT major_version_number\n",
    "    FROM versions_data_df\n",
    "    where tool_id={id}\n",
    "    order by number\n",
    "\"\"\"\n",
    "df = sql_helper(sql)\n",
    "min_version = df.major_version_number.min()\n",
    "max_version = df.major_version_number.max()\n",
    "sql = f\"\"\"\n",
    "    select  \n",
    "        sum(\"detected in # of stacks\") as total_no_of_stack\n",
    "    from versions_data_df\n",
    "    where tool_id={id}\n",
    "\"\"\"\n",
    "total_stack_for_this_tools=sql_helper_one(sql)[0]\n",
    "sql = f\"\"\"\n",
    "    SELECT \n",
    "        version_id,number,major_version_number,released_at,trusted,\"detected in # of stacks\" as no_of_stack,        \n",
    "        ({max_version} - major_version_number) as major_version_difference,\n",
    "        CASE WHEN major_version_difference>1 THEN -2 WHEN major_version_difference=1 THEN -1 ELSE 0 END AS change_level,\n",
    "        ((no_of_stack/{total_stack_for_this_tools})*100) as percentage,\n",
    "        0 as cosine_distance\n",
    "    FROM versions_data_df\n",
    "    where tool_id={id}\n",
    "    order by number\n",
    "\"\"\"\n",
    "masterdb=duckdb.query(sql).to_df()\n",
    "\n",
    "\n",
    "# ->number[Exist in DB]\n",
    "# ->major_version_number[Exist in DB]\n",
    "# ->Weightage\n",
    "# ->trusted[Exist in DB]\n",
    "# ->released_at[Exist in DB]\n",
    "# ->detected in # of stacks[Exist in DB]\n",
    "# ->Change-level[High,Medium,Low][Need to Generate]\n",
    "# ->Percentage of stack[against total # of stack][Need to Generate]\n",
    "# ->Structured changelog[Documents][Need to Generate]\n",
    "# ->Target_Version[Suggestions][Need to Generate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql=f\"\"\"\n",
    "    select *\n",
    "    from masterdb\n",
    "    order by number\n",
    "\"\"\"\n",
    "sql_helper(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_list(i):\n",
    "    items=[]\n",
    "    for item in i.replace('\"','').replace(\"[\",'').replace(\"]\",'').split(\",\"):\n",
    "        items.append(item.strip())\n",
    "    return items\n",
    "\n",
    "def convert_to_documents(version_id, number, major_version_number, released_at,trusted, no_of_stack, major_version_difference, change_level,percentage):\n",
    "    document=f\"\"\"\n",
    "        Description:\n",
    "            This document represent information about recommendation of solution based on user inputted query.\n",
    "            Where user need an answer in form of recommandation for perticular scenario.\n",
    "            It's following information\n",
    "            version_id: {version_id}\n",
    "            number: {number}\n",
    "            major_version_number: {major_version_number}\n",
    "            released_at: {released_at}\n",
    "            trusted: {trusted}\n",
    "            no_of_stack: {no_of_stack}\n",
    "            major_version_difference: {major_version_difference}\n",
    "            change_level: {change_level}\n",
    "            percentage: {percentage}\n",
    "            It'll help to recognize recommendation\n",
    "    \"\"\"\n",
    "    return document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Document class\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "document_ids=[]\n",
    "original_docs=[]\n",
    "for inx,item in masterdb.iterrows():\n",
    "    # print(item)\n",
    "    initial_content = convert_to_documents(item.version_id,item.number,item.major_version_number,item.released_at,item.trusted,item.no_of_stack,item.major_version_difference,item.change_level,item.percentage)\n",
    "    document_id = str(item.version_id)\n",
    "    # Create an instance of Document with initial content and metadata\n",
    "    original_doc = Document(page_content=initial_content, metadata={\"version_id\":item.version_id,\"number\":item.number,\"major_version_number\":item.major_version_number,\"released_at\":item.released_at,\"trusted\":item.trusted,\"no_of_stack\":item.no_of_stack,\"major_version_difference\":item.major_version_difference,\"change_level\":item.change_level,\"percentage\":item.percentage})\n",
    "    document_ids.append(document_id)\n",
    "    original_docs.append(original_doc)\n",
    "    # Initialize a Chroma instance with the original document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_db = Chroma.from_documents(\n",
    "    collection_name=\"version_collection\",\n",
    "    documents=original_docs,\n",
    "    embedding=embeddings,\n",
    "    ids=document_ids,\n",
    "    persist_directory='/workspaces/codesandbox-template-blank/Code_for_Embeddings/db_recommendation'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_db.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_db=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "persist_directory = '/workspaces/codesandbox-template-blank/Code_for_Embeddings/db_recommendation'\n",
    "vectordb = Chroma(persist_directory=persist_directory, embedding_function=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb.similarity_search('recommandation for perticular scenario')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_parquet(\"./db_recommendation/chroma-embeddings.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

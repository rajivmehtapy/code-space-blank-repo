{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U duckdb\n",
    "# !pip install -U langchain openai cohere\n",
    "# !pip install -U unstructured chromadb\n",
    "# !pip install -U tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"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\"\n",
    "os.environ[\"COHERE_API_KEY\"] = \"3vwcW4Gu0m5XWaT5bx4PBJ8IiQ5rT11rSsMijTBu\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "account_vulnerabilities_df=pd.read_csv('/workspace/gptexp/Code_for_Embeddings/data/account_vulnerabilities.csv')\n",
    "public_tools_df=pd.read_csv('/workspace/gptexp/Code_for_Embeddings/data/public_tools.csv')\n",
    "versions_data_df=pd.read_csv('/workspace/gptexp/Code_for_Embeddings/data/versions_data.csv')\n",
    "vulnerabilities_df=pd.read_csv('/workspace/gptexp/Code_for_Embeddings/data/vulnerabilities.csv')\n",
    "decisions_data_df=pd.read_csv('/workspace/gptexp/Code_for_Embeddings/data/decisions_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "\n",
    "sql = \"\"\"\n",
    "    SELECT  id,upvotes_count, raw_content,tools_names,high_quality\n",
    "    FROM decisions_data_df\n",
    "    Where type='GiveAdviceDecision'\n",
    "\"\"\"\n",
    "\n",
    "target_records=duckdb.query(sql).to_df()\n",
    "# duckdb.query(sql).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_list(i):\n",
    "    items=[]\n",
    "    for item in i.replace('\"','').replace(\"[\",'').replace(\"]\",'').split(\",\"):\n",
    "        items.append(item.strip())\n",
    "    return items\n",
    "\n",
    "def convert_to_documents(id,raw_content,upvotes_count,tools_names,high_quality):\n",
    "    document=f\"\"\"\n",
    "        Description:\n",
    "            This document represent information about recommandation of solution based on user inputted query.\n",
    "            Where user need an answer in form of recommandation for perticular scenario.\n",
    "            It's following information\n",
    "            Decision ID: {id}\n",
    "            Following is community answer:\\n {raw_content}\n",
    "            Here is response from community that represent as upvote score:{upvotes_count} \n",
    "            These are the list of related tool name: {','.join(convert_to_list(tools_names)) if len(convert_to_list(tools_names)) != 0 else ''}. \n",
    "            for this particular decision,\n",
    "            It'll help to recognize recommendation\n",
    "    \"\"\"\n",
    "    return document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "import os\n",
    "from langchain.embeddings import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.docstore.document import Document\n",
    "documents=[]\n",
    "doc_ids=[]\n",
    "for item in target_records.iterrows():\n",
    "    initial_content = convert_to_documents(item[1].id,item[1].raw_content,item[1].upvotes_count,item[1].tools_names,item[1].high_quality)\n",
    "    document_id = str(item[1].id)\n",
    "    # with open(f'/content/documents/{item[1].id}.txt','w') as file:\n",
    "    #     file.write(initial_content)\n",
    "    original_doc = Document(page_content=initial_content, metadata={\"id\": item[1].id,\"upvotes_count\":item[1].upvotes_count,\"tools_names\":item[1].tools_names,\"high_quality\":item[1].high_quality})\n",
    "    documents.append(original_doc)\n",
    "    doc_ids.append(item[1].id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter,RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=20)\n",
    "raw_docs = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "os.environ[\"OPENAI_API_KEY\"]= \"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\"\n",
    "persist_directory = '/workspace/gptexp/Code_for_Embeddings/db'\n",
    "vectordb = Chroma.from_documents(documents=raw_docs, \n",
    "                                 embedding=OpenAIEmbeddings(openai_api_key=\"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\"),\n",
    "                                 persist_directory=persist_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectordb.persist()\n",
    "# vectordb=None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_directory = '/workspace/gptexp/Code_for_Embeddings/db'\n",
    "embedding=OpenAIEmbeddings(openai_api_key=\"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\")\n",
    "vectordb = Chroma(persist_directory=persist_directory, embedding_function=embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_docs=vectordb.similarity_search_with_score('PHP',K=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Why PHP?** {'id': 15171, 'upvotes_count': 9, 'tools_names': '[]', 'high_quality': True}\n",
      "**Why PHP?** {'source': '/content/documents/15171.txt'}\n",
      "PHP. PHP has the largest market share of all the web-based software languages (close to 80% of all websites use PHP). Also, Laravel is the fastest-growing software framework based on PHP making it a wise choice. {'source': '/content/documents/13703.txt'}\n",
      "PHP. PHP has the largest market share of all the web-based software languages (close to 80% of all websites use PHP). Also, Laravel is the fastest-growing software framework based on PHP making it a wise choice. {'id': 13703, 'upvotes_count': 9, 'tools_names': '[]', 'high_quality': True}\n"
     ]
    }
   ],
   "source": [
    "result=''\n",
    "for i in search_docs[:10]:#raw_docs[:4]:\n",
    "    print(i[0].page_content,i[0].metadata)\n",
    "    result+=i[0].page_content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The answer is PHP is the most popular web-based software language. It has the largest market share of all the web-based software languages (close to 80% of all websites use PHP). Also, Laravel is the fastest-growing software framework based on PHP making it a wise choice.'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms import Cohere\n",
    "from langchain import PromptTemplate\n",
    "llm = Cohere(model=\"command-nightly\",temperature=0,max_tokens=300)\n",
    "template = \"\"\"/\n",
    "    Summarize following article:\n",
    "    {artical} \n",
    "\"\"\"\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "llm.predict(prompt.format(artical=result))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Misc Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.document_loaders import TextLoader\n",
    "# from langchain.document_loaders import DirectoryLoader\n",
    "# loader = DirectoryLoader('/content/documents/', glob=\"./*.txt\", loader_cls=TextLoader)\n",
    "# documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "persist_directory = '/content/dbazure'\n",
    "\n",
    "os.environ[\"OPENAI_API_TYPE\"] = \"azure\"\n",
    "os.environ[\"OPENAI_API_VERSION\"] = \"2023-03-15-preview\"\n",
    "os.environ[\"OPENAI_API_BASE\"] = \"https://stackgptembeddings.openai.azure.com/\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"fb2f2c8d261d4d17808019a8ab64ee35\"\n",
    "# embeddings = OpenAIEmbeddings()\n",
    "\n",
    "\n",
    "vectordb = Chroma.from_documents(documents=raw_docs, \n",
    "                                 embedding=OpenAIEmbeddings(openai_api_key=\"fb2f2c8d261d4d17808019a8ab64ee35\"),\n",
    "                                 persist_directory=persist_directory)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

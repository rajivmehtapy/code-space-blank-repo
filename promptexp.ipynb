{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install cohere\n",
    "# !pip install langchain openai\n",
    "# !pip install unstructured chromadb\n",
    "# !pip install tiktoken\n",
    "# !pip install duckdb\n",
    "# !pip install -U pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import duckdb\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', 180) \n",
    "path = '/workspaces/codesandbox-template-blank/Code_for_Embeddings'\n",
    "\n",
    "account_vulnerabilities_df=pd.read_csv(f'{path}/data/account_vulnerabilities.csv')\n",
    "public_tools_df=pd.read_csv(f'{path}/data/public_tools.csv')\n",
    "versions_data_df=pd.read_csv(f'{path}/data/versions_data.csv')\n",
    "vulnerabilities_df=pd.read_csv(f'{path}/data/vulnerabilities.csv')\n",
    "decisions_data_df=pd.read_csv(f'{path}/data/decisions_data.csv')\n",
    "parameters_data_df=pd.read_excel(f'{path}/data/parameters.xlsx')\n",
    "\n",
    "import duckdb\n",
    "duckdb.default_connection.execute(\"SET GLOBAL pandas_analyze_sample=100000\")\n",
    "def sql_helper(sql):\n",
    "    return duckdb.query(sql).to_df()\n",
    "\n",
    "def sql_helper_one(sql):\n",
    "    return duckdb.query(sql).fetchone()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import duckdb\n",
    "sql=f\"\"\"\n",
    "    select *\n",
    "    from public_tools_df\n",
    "    limit 5\n",
    "\"\"\"\n",
    "sql_helper(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql=f\"\"\"\n",
    "    select * \n",
    "    from parameters_data_df\n",
    "\"\"\"\n",
    "df=sql_helper(sql)\n",
    "\n",
    "def proc(x):\n",
    "    for inx,item in x.Parameters.items():\n",
    "        x.Parameters.iloc[inx]='_'.join(item.replace('-',' ').split(' '))\n",
    "    return x.Parameters\n",
    "\n",
    "df = df.assign(Formatted_Parameters=proc)\n",
    "\n",
    "sql=f\"\"\"\n",
    "    select Formatted_Parameters as Parameters,\"Weightage \" as Weightage\n",
    "    from df\n",
    "\"\"\"\n",
    "sql_helper(sql).to_csv('parameters.csv',index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql=f\"\"\"\n",
    "    select number,tool_id,tool_name,major_version_number,'' as max_version_number,\n",
    "    0 as Freshness_Distance_from_latest_version,\n",
    "    0 as tool_version_External_Factors_Freshness_EOL_Support,\n",
    "    0 as tool_version_External_Factors_Last_commit_date_of_the_package,\n",
    "    0 as tool_version_External_Factors_Security_Vulnerabilities,\n",
    "    0 as tool_version_Internal_Factors_Adoption_Adoption_Stages,\n",
    "    0 as tool_version_Internal_Factors_Adoption_Internal_Adoption_Skill_set_Availability,\n",
    "    0 as tool_version_Internal_Factors_cost\n",
    "    from versions_data_df\n",
    "    where tool_id=2739\n",
    "    order by number\n",
    "\"\"\"\n",
    "df_Freshness_Distance_from_latest_version=sql_helper(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Freshness_Distance_from_latest_version"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Security Vulnerabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import duckdb\n",
    "sql=f\"\"\"\n",
    "    select \n",
    "        * \n",
    "    from \n",
    "        vulnerabilities_df\n",
    "    limit 5\n",
    "\"\"\"\n",
    "# df= sql_helper(sql)\n",
    "\n",
    "sql_helper(sql)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql=f\"\"\"\n",
    "    select vdd.number,vd.severity,vdd.tool_id\n",
    "    from versions_data_df as vdd\n",
    "    inner join vulnerabilities_df as vd\n",
    "    on vdd.tool_id = vd.tool_id\n",
    "    where vdd.tool_id=2739   \n",
    "    order by vdd.number\n",
    "\"\"\"\n",
    "# sql=f\"\"\"\n",
    "#     select max(vdd.tool_id)\n",
    "#     from vulnerabilities_df as vdd\n",
    "# \"\"\"\n",
    "sql_helper(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "babel_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "babel_version.to_csv('gd.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for inx,item in babel_version.iterrows():\n",
    "    print(item.number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.llms import AzureOpenAI,Cohere,OpenAI,GooglePalm\n",
    "\n",
    "# llm = AzureOpenAI(\n",
    "#     deployment_name=\"StackGPT35Turbo\",\n",
    "#     model_name=\"gpt-35-turbo\",\n",
    "#     temperature=0,\n",
    "#     max_tokens=10 \n",
    "# )\n",
    "# llm = Cohere(model=\"command-xlarge-beta\",temperature=0,max_tokens=10,k=0)\n",
    "llm=GooglePalm(temperature=0,max_output_tokens=10,top_p=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "def prompt_generation(current_tool_version,latest_tool_version):\n",
    "    print(f'current_tool_version --> {current_tool_version}')\n",
    "    template = f\"\"\"You are excellent AI assistant.You known to identify and quantize distance between two nodes.\n",
    "    If we lable distance between in range of 1 - 5.\n",
    "    that is if it's very near than label it as 1 and if it is too far\n",
    "    it should label as 5. \n",
    "    For example\n",
    "\n",
    "    if node1 is 1.0 and node2 is 2.0 than distance rank is 1.\n",
    "    if node1 is 1.0 and node2 is 3.0 than distance rank is 2.\n",
    "    if node1 is 1.0 and node2 is 4.0 than distance rank is 3.\n",
    "    if node1 is 1.0 and node2 is 5.0 than distance rank is 4.\n",
    "    if node1 is 5.0.0 and node2 is 5.2.0 than distance rank is 0.\n",
    "    if node1 is 3.3.0 and node2 is 3.2.0 than distance rank is 0.\n",
    "    if node1 is 4.4.0 and node2 is 5.2.0 than distance rank is 1.\n",
    "    if node1 is 4.4.0-beta.8 and node2 is 5.5.0 than distance rank is 1.\n",
    "    \n",
    "    if node1 is 6.13.1 and node2 is 7.9.6 than distance rank is 1.\n",
    "    if node1 is 6.14.0 and node2 is 7.9.6 than distance rank is 1.\n",
    "    if node1 is 6.15.2 and node2 is 7.9.6 than distance rank is 1.\n",
    "    if node1 is 6.21.0 and node2 is 7.9.6 than distance rank is 1.\n",
    "    if node1 is 6.23.1 and node2 is 7.9.6 than distance rank is 1.\n",
    "    if node1 is 6.3.1 and node2 is 7.9.6 than distance rank is 1.\n",
    "    \n",
    "    if node1 is 7.0.0-beta.54 and node2 is 7.9.6 than distance rank is 1.\n",
    "\n",
    "\n",
    "        there is node1 is {current_tool_version} and node2 is {latest_tool_version}.\n",
    "\n",
    "    now can you respond me what is the difference between node1 and node2 in terms of \n",
    "    rank between 1 to 5.\n",
    "    Kindly give me response in one word only no need to verbose.\n",
    "    Response:\n",
    "    \"\"\"\n",
    "    return template\n",
    "\n",
    "def convert_tool_version_External_Factors_Freshness_Distance_from_latest_version(response):\n",
    "    print(f'Response --> {response}')\n",
    "    internal_weitage=0\n",
    "    rank=int(response)\n",
    "    if rank >= 3 and rank <= 5:\n",
    "        internal_weitage = 50\n",
    "    elif rank >= 1 and rank <= 2: \n",
    "        internal_weitage = 90\n",
    "    else:\n",
    "        internal_weitage = 100\n",
    "\n",
    "    return((internal_weitage/100)*5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = prompt_generation(\"6.18.2\",\"7.9.6\")\n",
    "response=llm(template)\n",
    "convert_response_to_score=convert_tool_version_External_Factors_Freshness_Distance_from_latest_version(response)\n",
    "convert_response_to_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Freshness_Distance_from_latest_version.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import time\n",
    "for i,row in df_Freshness_Distance_from_latest_version.iterrows():\n",
    "    df_Freshness_Distance_from_latest_version.at[i,'max_version_number'] = \"7.9.6\"\n",
    "    # print(f'data --> {row.number}')    \n",
    "    # template = prompt_generation(row.number,\"7.9.6\")\n",
    "    # response=llm(template)\n",
    "    # df_Freshness_Distance_from_latest_version.at[i,'Freshness_Distance_from_latest_version']=convert_tool_version_External_Factors_Freshness_Distance_from_latest_version(response)\n",
    "    time.sleep(3)\n",
    "\n",
    "df_Freshness_Distance_from_latest_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Freshness_Distance_from_latest_version.to_excel(\"result.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
